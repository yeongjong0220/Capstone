import mysql.connector
from openai import OpenAI
from pinecone import Pinecone, ServerlessSpec
import os
from dotenv import load_dotenv
import time
from datetime import datetime

# -----------------------------------------------
# 0. ì„¤ì • ë¡œë“œ
# -----------------------------------------------
print("ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
load_dotenv()

# OpenAI ì„¤ì •
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIMENSION = 1536

# Pinecone ì„¤ì •
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = "job-postings-index"

# DB ì„¤ì •
db_config = {
    'host': 'capstone-choi.c21iu2qqwmva.us-east-1.rds.amazonaws.com',
    'user': 'root',
    'password': os.getenv("DB_PASSWORD"),
    'database': os.getenv("DB_NAME") 
}
TABLE_NAME = "job_postings"
BATCH_SIZE = 100 
CHECK_INTERVAL = 60 # 60ì´ˆ(1ë¶„)ë§ˆë‹¤ í™•ì¸

# -----------------------------------------------
# 1. Pinecone ì´ˆê¸°í™” (ìµœì´ˆ 1íšŒ)
# -----------------------------------------------
pc = Pinecone(api_key=PINECONE_API_KEY)

if PINECONE_INDEX_NAME not in pc.list_indexes().names():
    print(f"'{PINECONE_INDEX_NAME}' ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    pc.create_index(
        name=PINECONE_INDEX_NAME,
        dimension=EMBEDDING_DIMENSION,
        metric="cosine",
        spec=ServerlessSpec(cloud='aws', region='us-east-1')
    )
    while not pc.describe_index(PINECONE_INDEX_NAME).status['ready']:
        time.sleep(1)

index = pc.Index(PINECONE_INDEX_NAME)
print("âœ… Pinecone ì¸ë±ìŠ¤ ì—°ê²° ì™„ë£Œ. ìë™í™” ì‹œìŠ¤í…œì„ ê°€ë™í•©ë‹ˆë‹¤.\n")

# -----------------------------------------------
# 2. ê³µê³  ì²˜ë¦¬ í•¨ìˆ˜
# -----------------------------------------------
def process_new_postings():
    conn = None
    try:
        conn = mysql.connector.connect(**db_config)
        # dictionary=True: DB ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ {key: value} í˜•íƒœë¡œ ê°€ì ¸ì˜´
        cursor = conn.cursor(dictionary=True)

        # [í•µì‹¬ ì¿¼ë¦¬ ìˆ˜ì •]
        # statusê°€ 'published' ì¸ ê²ƒë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤. (draft ì œì™¸)
        # approved='Y', del='N', is_embedded='N' ì¡°ê±´ë„ í¬í•¨
        query = f"""
            SELECT * FROM {TABLE_NAME} 
            WHERE status = 'published' 
            AND approved = 'Y' 
            AND del = 'N' 
            AND (is_embedded = 'N' OR is_embedded IS NULL)
        """
        cursor.execute(query)
        new_data = cursor.fetchall()

        if not new_data:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] ìƒˆë¡œìš´ ê²Œì‹œ ê³µê³  ì—†ìŒ. ëŒ€ê¸° ì¤‘...")
            return

        print(f"\nğŸ“¢ {len(new_data)}ê°œì˜ 'ê²Œì‹œë¨(published)' ê³µê³  ë°œê²¬! ì²˜ë¦¬ ì‹œì‘...")

        vectors_to_upsert = []
        processed_ids = [] 

        for row in new_data:
            try:
                # (A) ì„ë² ë”© í…ìŠ¤íŠ¸ ì¡°í•©
                text_to_embed = f"ì œëª©: {row['title']}\nìš”ì•½: {row.get('summary', '')}\në‚´ìš©: {row['content']}"

                # (B) ì„ë² ë”© ìƒì„±
                response = openai_client.embeddings.create(
                    input=text_to_embed,
                    model=EMBEDDING_MODEL
                )
                vector = response.data[0].embedding

                # (C) ë©”íƒ€ë°ì´í„° ì¤€ë¹„ (ë¦¬ìŠ¤íŠ¸ ë³€í™˜ í¬í•¨)
                tags_list = [t.strip() for t in row['tags'].split(',')] if row.get('tags') else []
                audience_list = [a.strip() for a in row['target_audience'].split(',')] if row.get('target_audience') else []

                metadata = {
                    "title": row.get('title'),
                    "status": row.get('status'), # ë©”íƒ€ë°ì´í„°ì—ë„ status í¬í•¨
                    "summary": row.get('summary'),
                    "job_category": row.get('job_category'),
                    "employment_type": row.get('employment_type'),
                    "required_experience": row.get('required_experience'),
                    "region": row.get('region'),
                    "company_name": row.get('company_name'),
                    "source_url": row.get('source_url'),
                    "apply_method": row.get('apply_method'),
                    "apply_link": row.get('apply_link'),
                    "tags": tags_list,
                    "target_audience": audience_list,
                    "apply_start_date": row['apply_start_date'].isoformat() if row.get('apply_start_date') else None,
                    "apply_end_date": row['apply_end_date'].isoformat() if row.get('apply_end_date') else None,
                }

                vectors_to_upsert.append({
                    "id": str(row['post_id']),
                    "values": vector,
                    "metadata": metadata
                })
                
                processed_ids.append(row['post_id'])

            except Exception as e:
                print(f"âŒ ID {row['post_id']} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")

        # (D) Pinecone ì—…ë¡œë“œ & DB ì—…ë°ì´íŠ¸
        if vectors_to_upsert:
            index.upsert(vectors=vectors_to_upsert)
            print(f"âœ… Pineconeì— {len(vectors_to_upsert)}ê°œ ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ.")

            # DBì— 'ì²˜ë¦¬ì™„ë£Œ(Y)' í‘œì‹œ -> ë‹¤ìŒì— ë‹¤ì‹œ ì•ˆ ê°€ì ¸ì˜¤ê²Œ í•¨
            if processed_ids:
                format_strings = ','.join(['%s'] * len(processed_ids))
                update_query = f"UPDATE {TABLE_NAME} SET is_embedded = 'Y' WHERE post_id IN ({format_strings})"
                
                cursor = conn.cursor() # ë”•ì…”ë„ˆë¦¬ ì»¤ì„œ ë§ê³  ì¼ë°˜ ì»¤ì„œ ì‚¬ìš©
                cursor.execute(update_query, tuple(processed_ids))
                conn.commit()
                print(f"âœ… DB ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(processed_ids)}ê°œ ê³µê³  'is_embedded' -> 'Y'")

    except mysql.connector.Error as err:
        print(f"âš ï¸ DB ì—°ê²° ì˜¤ë¥˜: {err}")
    finally:
        if conn and conn.is_connected():
            conn.close()

# -----------------------------------------------
# 3. ë©”ì¸ ì‹¤í–‰ (ë¬´í•œ ë£¨í”„)
# -----------------------------------------------
if __name__ == "__main__":
    print("ğŸš€ ì‹¤ì‹œê°„ ê³µê³  ê°ì‹œ ì‹œìŠ¤í…œ(Status í•„í„° ì ìš©) ì‹œì‘ (Ctrl+Cë¡œ ì¢…ë£Œ)")
    
    try:
        while True:
            process_new_postings()
            time.sleep(CHECK_INTERVAL) # 60ì´ˆë§ˆë‹¤ ë°˜ë³µ
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")