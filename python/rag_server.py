import os
from fastapi import FastAPI
from pydantic import BaseModel
from uvicorn import run
from dotenv import load_dotenv

# LangChain ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore

# â­ï¸ ìˆ˜ì •ë¨ 1/7: RetrievalQA ëŒ€ì‹  ConversationalRetrievalChain ì„í¬íŠ¸
from langchain.chains import ConversationalRetrievalChain 
from langchain.prompts import PromptTemplate
from typing import List, Dict, Any

# --- 1. .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ ---
load_dotenv()

# .env íŒŒì¼ì— í‚¤ê°€ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
if not os.getenv("PINECONE_API_KEY"):
    raise ValueError("PINECONE_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# --- 2. (âš ï¸ ì¤‘ìš”) ì‚¬ìš©ìê°€ ì§ì ‘ ìˆ˜ì •í•  ë¶€ë¶„ ---
PINECONE_INDEX_NAME = "policy-chatbot"
# ---------------------------------------------

if PINECONE_INDEX_NAME == "your-pinecone-index-name-here":
    raise ValueError("PINECONE_INDEX_NAMEì„ rag_server.py ì½”ë“œ ë‚´ì—ì„œ ì§ì ‘ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.")


# --- 3. RAG ì±—ë´‡ í•µì‹¬ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™” ---
try:
    print("RAG ì±—ë´‡ êµ¬ì„± ìš”ì†Œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")

    # 1. LLM (ì–¸ì–´ ëª¨ë¸, ì˜ˆ: GPT-3.5)
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0.0
    )

    # 2. Embedding Model (í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # 3. Vector Store (Pinecone ì¸ë±ìŠ¤ì— ì—°ê²°)
    vectorstore = PineconeVectorStore.from_existing_index(
        index_name=PINECONE_INDEX_NAME,
        embedding=embeddings,
        text_key="embedding_text"
    )

    # 4. Retriever (ë²¡í„° ì €ì¥ì†Œì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰)
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={'k': 3}
    )

    # 5. Prompt Template (ì´ì „ê³¼ ë™ì¼, {chat_history} ë³€ìˆ˜ í¬í•¨)
    prompt_template = """
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ 'ì§€ì—­ ì •ì±…'ì„ ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì•ˆë‚´í•˜ëŠ” ì „ë¬¸ AI ì±—ë´‡ì…ë‹ˆë‹¤.
    í•­ìƒ ì‚¬ìš©ìì˜ ê´€ì ì—ì„œ ìƒê°í•˜ë©°, ëª…í™•í•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

    [ë‹µë³€ ìƒì„± 5ì›ì¹™]
    1.  **ì¹œì ˆí•œ ë§íˆ¬:** í•­ìƒ ìƒëƒ¥í•˜ê³  ì¹œì ˆí•œ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ë©°, ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ìš©ì–´ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. (ì˜ˆ: "ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì€...")
    2.  **ê¹”ë”í•œ í˜•ì‹:** ë‹µë³€ì´ ê¸¸ì–´ì§ˆ ê²½ìš°, ì‚¬ìš©ìê°€ ì½ê¸° í¸í•˜ë„ë¡ **ì¤„ë°”ê¿ˆ**, **ê¸€ë¨¸ë¦¬ ê¸°í˜¸(â€¢)**, **ë²ˆí˜¸ ë§¤ê¸°ê¸°**ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©í•´ ë‚´ìš©ì„ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•´ ì£¼ì„¸ìš”.
    3.  **ê·¼ê±° ê¸°ë°˜ ë‹µë³€:** ë‹µë³€ì€ ë°˜ë“œì‹œ ì•„ë˜ [ì°¸ê³  ìë£Œ]ì— ê·¼ê±°í•´ì•¼ í•©ë‹ˆë‹¤. ìë£Œì— ì—†ëŠ” ë‚´ìš©ì„ ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
    
    4.  **(âš ï¸ìˆ˜ì •ë¨) í•µì‹¬ ì •ë³´ ê°•ì¡°:**
        * [ì°¸ê³  ìë£Œ]ì— 'ì‹ ì²­ë°©ë²•', 'ë¬¸ì˜ì²˜', 'ëŒ€ìƒ' ë“± ì‚¬ìš©ìê°€ ê¶ê¸ˆí•´í•  ë§Œí•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ë‹µë³€ì— ì•Œê¸° ì‰½ê²Œ í¬í•¨ì‹œì¼œ ì£¼ì„¸ìš”.
        * **[ì¤‘ìš”] ë§Œì•½ [ì°¸ê³  ìë£Œ]ì˜ 'ì‹ ì²­ë°©ë²•' ë“±ì— 'http://' ë˜ëŠ” 'https://'ë¡œ ì‹œì‘í•˜ëŠ” ì‹¤ì œ ì›¹ ì£¼ì†Œ(URL)ê°€ ëª…í™•íˆ í¬í•¨ë˜ì–´ ìˆëŠ” ê²½ìš°ì—ë§Œ, í•´ë‹¹ ë§í¬ë¥¼ ì œì‹œí•´ ì£¼ì„¸ìš”.**
        * **ìë£Œì— ì‹¤ì œ URLì´ ì—†ë‹¤ë©´, ì ˆëŒ€ ê°€ìƒì˜ ë§í¬(ì˜ˆ: '[ë°”ë¡œê°€ê¸°]')ë¥¼ ì§€ì–´ë‚´ê±°ë‚˜ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.**

    5.  **ì •ì¤‘í•œ ê±°ì ˆ:** [ì°¸ê³  ìë£Œ]ë¥¼ ê²€í† í•´ë„ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, "ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë”±ë”±í•˜ê²Œ ë§í•˜ì§€ ë§ê³ , "ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•œ ì •ì±… ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¡œ ì§ˆë¬¸í•´ ì£¼ì‹œê² ì–´ìš”?"ì™€ ê°™ì´ ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

    ---
    (ì°¸ê³ : ì•„ë˜ [ì´ì „ ëŒ€í™” ê¸°ë¡]ì€ ë‹µë³€ ìƒì„±ì„ ìœ„í•œ ë§¥ë½ ì •ë³´ì…ë‹ˆë‹¤.)
    
    [ì´ì „ ëŒ€í™” ê¸°ë¡]
    {chat_history}
    
    (ì°¸ê³ : ì•„ë˜ [ì°¸ê³  ìë£Œ]ëŠ” í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.)

    [ì°¸ê³  ìë£Œ]
    {context}

    [ì§ˆë¬¸]
    {question}

    [ì¹œì ˆí•œ ë‹µë³€]
    """
    
    PROMPT = PromptTemplate(
        template=prompt_template, input_variables=["context", "question", "chat_history"]
    )

    # â­ï¸ ìˆ˜ì •ë¨ 2/7: 'RetrievalQA' ëŒ€ì‹  'ConversationalRetrievalChain' ì‚¬ìš©
    # ì´ ì²´ì¸ì€ 'question'ê³¼ 'chat_history'ë¥¼ ì…ë ¥ë°›ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        # 'combine_docs_chain_kwargs'ë¥¼ í†µí•´ RAG í”„ë¡¬í”„íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
        combine_docs_chain_kwargs={"prompt": PROMPT},
        return_source_documents=True
    )

    print("âœ… RAG ì±—ë´‡ ì²´ì¸ ì´ˆê¸°í™” ì™„ë£Œ.")

except Exception as e:
    print(f"ğŸš¨ RAG ì´ˆê¸°í™” ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("API í‚¤, Pinecone ì¸ë±ìŠ¤ ì´ë¦„, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    exit(1)


# --- 4. FastAPI ì„œë²„ ì„¤ì • ---
app = FastAPI()

# Node.jsë¡œë¶€í„° ë°›ì„ ë°ì´í„° ëª¨ë¸ (ì´ì „ê³¼ ë™ì¼)
class ChatRequest(BaseModel):
    message: str
    history: List[Dict[str, Any]] = []

# Node.jsì—ê²Œ ë³´ë‚¼ ë°ì´í„° ëª¨ë¸ (ì´ì „ê³¼ ë™ì¼)
class ChatResponse(BaseModel):
    answer: str
    source: str | None = None

@app.post("/ask", response_model=ChatResponse)
async def ask_question(request: ChatRequest):
    """
    Node.js ë°±ì—”ë“œë¡œë¶€í„° ì§ˆë¬¸ê³¼ ëŒ€í™” ê¸°ë¡ì„ ë°›ì•„ RAG ì±—ë´‡ì„ ì‹¤í–‰í•˜ê³  ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        user_message = request.message
        chat_history_list = request.history
        
        print(f"Node.jsë¡œë¶€í„° ë°›ì€ ì§ˆë¬¸: {user_message}")
        print(f"Node.jsë¡œë¶€í„° ë°›ì€ ëŒ€í™” ê¸°ë¡ ìˆ˜: {len(chat_history_list)}ê°œ")

        # â­ï¸ ìˆ˜ì •ë¨ 3/7: 'history' í˜•ì‹ì„ List[Dict]ì—ì„œ List[Tuple[str, str]]ë¡œ ë³€í™˜
        # (ConversationalRetrievalChainì´ ìš”êµ¬í•˜ëŠ” í˜•ì‹)
        # ë³€í™˜ ëŒ€ìƒ: [{'sender': 'user', 'text': 'Q1'}, {'sender': 'bot', 'text': 'A1'}]
        # ë³€í™˜ ê²°ê³¼: [('Q1', 'A1')]
        formatted_history = []
        user_msg = None
        for turn in chat_history_list:
            if turn.get("sender") == "user":
                user_msg = turn.get("text", "")
            elif turn.get("sender") == "bot" and user_msg is not None:
                # 'user' ë©”ì‹œì§€ ë‹¤ìŒì— 'bot' ë©”ì‹œì§€ê°€ ì˜¤ë©´ ì§ì„ ì´ë¤„ ì¶”ê°€
                formatted_history.append((user_msg, turn.get("text", "")))
                user_msg = None # ë‹¤ìŒ ì§ì„ ìœ„í•´ ì´ˆê¸°í™”

        # â­ï¸ ìˆ˜ì •ë¨ 4/7: 'invoke'ì— 'question'ê³¼ 'chat_history' (íŠœí”Œ ë¦¬ìŠ¤íŠ¸) ì „ë‹¬
        response = qa_chain.invoke({
            "question": user_message, 
            "chat_history": formatted_history
        })
        
        # â­ï¸ ìˆ˜ì •ë¨ 5/7: 'ConversationalRetrievalChain'ì˜ ë‹µë³€ í‚¤ëŠ” 'result'ê°€ ì•„ë‹Œ 'answer'
        bot_reply = response['answer']
        
        source_doc = "ì¶œì²˜ ì •ë³´ ì—†ìŒ"
        if response.get('source_documents'):
            source_doc = response['source_documents'][0].metadata.get('policy_name', 'ì¶œì²˜ ì •ë³´ ì—†ìŒ')

        print(f"LLMì´ ìƒì„±í•œ ë‹µë³€: {bot_reply}")
        print(f"ë‹µë³€ ê·¼ê±°: {source_doc}")

        # Node.jsì—ê²Œ JSON í˜•íƒœë¡œ ë‹µë³€ ë°˜í™˜
        return {"answer": bot_reply, "source": source_doc}

    except Exception as e:
        print(f"ğŸš¨ RAG ì„œë²„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return {"answer": "ì£„ì†¡í•©ë‹ˆë‹¤, Python RAG ì„œë²„ì—ì„œ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "source": None}


# --- 5. API ì„œë²„ ì‹¤í–‰ ---
if __name__ == "__main__":
    
    # --- â¬‡ï¸ (ìˆ˜ì •ë¨) ì„œë²„ ì‹œì‘ ì „, RAG ì²´ì¸ ì§ì ‘ í…ŒìŠ¤íŠ¸ (ë©€í‹°í„´ ë°˜ì˜) â¬‡ï¸ ---
    print("--- [RAG ì²´ì¸ ì§ì ‘ í…ŒìŠ¤íŠ¸ ì‹œì‘] ---")
    try:
        test_query = "ê·¸ëŸ¼ ìê²© ì¡°ê±´ì€ ë­ì•¼?" 
        
        # â­ï¸ ìˆ˜ì •ë¨ 6/7: í…ŒìŠ¤íŠ¸ìš© 'chat_history'ë¥¼ íŠœí”Œ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€ê²½
        test_history_tuples = [
            ("ê´‘ì£¼ê´‘ì—­ì‹œ ì²­ë…„ ì •ì±… ì•Œë ¤ì¤˜", "ë„¤, ê´‘ì£¼ê´‘ì—­ì‹œ ì²­ë…„ ì •ì±…ìœ¼ë¡œëŠ” ... (ê°€ìƒ ë‹µë³€) ... ì´ ìˆìŠµë‹ˆë‹¤.")
        ]
        
        test_response = qa_chain.invoke({
            "question": test_query,
            "chat_history": test_history_tuples
        })
        
        print(f"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_query}")
        # â­ï¸ ìˆ˜ì •ë¨ 7/7: í…ŒìŠ¤íŠ¸ ë‹µë³€ í‚¤ë„ 'answer'ë¡œ ë³€ê²½
        print(f"í…ŒìŠ¤íŠ¸ ë‹µë³€: {test_response['answer']}")
        
        if test_response.get('source_documents'):
            print(f"í…ŒìŠ¤íŠ¸ ê·¼ê±°: {test_response['source_documents'][0].metadata.get('policy_name', 'N/A')}")
        else:
            print("í…ŒìŠ¤íŠ¸ ê·¼ê±°: (ê·¼ê±° ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨)")
            
        print("--- [âœ… RAG ì²´ì¸ ì§ì ‘ í…ŒìŠ¤íŠ¸ ì„±ê³µ] ---")

    except Exception as e:
        print(f"--- [ğŸš¨ RAG ì²´ì¸ ì§ì ‘ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨] ---")
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("-----------------------------------")
    # --- â¬†ï¸ í…ŒìŠ¤íŠ¸ ì½”ë“œ ì¢…ë£Œ â¬†ï¸ ---

    print(f"Python RAG API ì„œë²„ë¥¼ 8001ë²ˆ í¬íŠ¸ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤ (http://localhost:8001)")
    run(app, host="0.0.0.0", port=8001)